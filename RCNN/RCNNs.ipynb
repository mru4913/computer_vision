{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region-based CNNs\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "### 1.0 RCNN\n",
    "### 2.0 Fast RCNN \n",
    "### 3.0 Faster RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection contains two main steps:\n",
    "* Locate bounding boxes containing objects, where each box contain only one object \n",
    "* Classify object inside each bounding boxe and assign label to it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 [RCNN](https://arxiv.org/pdf/1311.2524.pdf) (2013)\n",
    "\n",
    "RCNN was a pioneering approach that applies deep models to object detection, which was introduced by Ross Girshick et al. It is the first CNN that dramatically increases the performance of object detection, with 58.5 mAP on VOC-2007 image dataset.\n",
    "\n",
    "![](./img/rcnn.png)\n",
    "\n",
    "### Process\n",
    "\n",
    "- **1.0** Select multiple high-quality proposed regions from the input image using *SELECTIVE SEARCH* algorithm. These regions are selected with different scales and different shapes. Then label each region class and its bounding box coordinates.\n",
    "- **2.0** A well pretrained CNN (usually VGG or Resnet) is used without the last layer(output layer orclassification layer). It transforms regions input the same input dimensions and performs forward computation to extracgt features from the regions\n",
    "- **3.0** The output features and labels of each proposed region are combined into 1D vector (as an instance) to train multiple support vectore machines for object classification. It means that for each class, it trains a SVM classifier.\n",
    "- **4.0** The output features and labels of each proposed regions are combined intwo 1D vector (as an instance) to train a linear regression model for bounding box prediction.\n",
    "\n",
    "\n",
    "### Key points\n",
    "\n",
    "- It is the first paper that introduce regioned proposed method to detect multiple objects in an image.\n",
    "- It proposes about ~2k regions from each image, which leads to massive forward computation and low efficiency.\n",
    "- It takes about 13s to predict an image on GPU and 53s on CPU.\n",
    "- It trans models (CNN. SVMs and regressor) separately （multi-stage training also needs more memory). There is no end to end training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 [Fast RCNN](https://arxiv.org/pdf/1504.08083.pdf) (2015)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The main performance bottleneck of an R-CNN model is the need to independently extract features for each proposed region. As these regions have a high degree of overlap, independent feature extraction results in a high volume of repetitive computations. Fast R-CNN improves on the R-CNN by only per- forming CNN forward computation on the image as a whole.\n",
    "\n",
    "\n",
    "1. Compared to an R-CNN model, a Fast R-CNN model uses the entire image as the CNN input for feature extraction, rather than each proposed region. Moreover, this network is generally trained to update the model parameters. As the input is an entire image, the CNN output shape is 1 × c × h1 ×w1.\n",
    "2. Assuming selective search generates n proposed regions, their different shapes indicate regions of interests (RoIs) of different shapes on the CNN output. Features of the same shapes must be extracted from these RoIs (here we assume that the height is h2 and the width is w2). Fast R-CNN introduces RoI pooling, which uses the CNN output and RoIs as input to output a concatenation of the features extracted from each proposed region with the shape n × c × h2 × w2.\n",
    "3. A fully connected layer is used to transform the output shape to n × d, where d is determined by the model design.\n",
    "4. During category prediction, the shape of the fully connected layer output is again transformed to n × q and we use software regression (q is the number of categories). During bounding box prediction, the shape of the fully connected layer output is again transformed to n × 4. This means that we predict the category and bounding box for each proposed region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Faster RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dsfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
