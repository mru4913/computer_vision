{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region-based CNNs\n",
    "\n",
    "## Table of Content\n",
    "\n",
    "### 1.0 RCNN\n",
    "### 2.0 Fast RCNN \n",
    "### 3.0 Faster RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object detection contains two main steps:\n",
    "* Locate bounding boxes containing objects, where each box contain only one object \n",
    "* Classify object inside each bounding boxe and assign label to it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 [RCNN](https://arxiv.org/pdf/1311.2524.pdf) (2013)\n",
    "\n",
    "RCNN was a pioneering approach that applies deep models to object detection, which was introduced by Ross Girshick et al. It is the first CNN that dramatically increases the performance of object detection, with 58.5 mAP on VOC-2007 image dataset.\n",
    "\n",
    "![](./img/rcnn.png)\n",
    "\n",
    "### Process\n",
    "\n",
    "- **1.0** Select multiple high-quality proposed regions from the input image using *SELECTIVE SEARCH* algorithm. These regions are selected with different scales and different shapes. Then label each region class and its bounding box coordinates.\n",
    "- **2.0** A well pretrained CNN (usually VGG or Resnet) is used without the last layer(output layer orclassification layer). It transforms regions input the same input dimensions and performs forward computation to extracgt features from the regions\n",
    "- **3.0** The output features and labels of each proposed region are combined into 1D vector (as an instance) to train multiple support vectore machines for object classification. It means that for each class, it trains a SVM classifier.\n",
    "- **4.0** The output features and labels of each proposed regions are combined intwo 1D vector (as an instance) to train a linear regression model for bounding box prediction.\n",
    "\n",
    "\n",
    "### Key points\n",
    "\n",
    "- It is the first paper that introduce regioned proposed method to detect multiple objects in an image.\n",
    "- It proposes about ~2k regions from each image, which leads to massive forward computation and low efficiency.\n",
    "- It randomly sample some positive examples (regions with object present) and negative examples (regions wihtout object present) during training.\n",
    "- It takes about 13s to predict an image on GPU and 53s on CPU.\n",
    "- It trans models (CNN. SVMs and regressor) separately （multi-stage training also needs more memory). There is no end to end training.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 [Fast RCNN](https://arxiv.org/pdf/1504.08083.pdf) (2015)\n",
    "\n",
    "The main problem with RCNN approach is:\n",
    "- ~2k proposed regions requires massive forward computation. Moreover, these regions highly overlap resulting in a high volume of repetitive computations.\n",
    "\n",
    "In the followup work by Ross Girshick, he proposed a method called Fast R-CNN that significantly speed up object detection. It results mAP 71.8 on VOC-2007–12 dataset achieves and 35.9 on COCO dataset.\n",
    "\n",
    "![](./img/frcnn.png)\n",
    "\n",
    "\n",
    "### Process\n",
    "\n",
    "- **1.0** Instead of forward computing ~2k feature maps in RCNN, a Fast RCNN generate only one feature map from the entire image as input. \n",
    "- **2.0** Selective search generates N proposals, thier different shapes indicate regions of interests (RoIs) of different shapes on the feature map. In order to keep the same shapes extracted from these RoIs, an RoI pooling layer is introduced to extracts a fixed-length feature vector, which is finally passed to subsequent FC layers.\n",
    "- **3.0** The shape of the FC layer output is transformed to N x (q+1) for object classification, wehere q is the number of classes and 1 indicates the background.\n",
    "- **4.0** The shape of the FC layer output is transformed to N x 4 for bounding boxes prediction. \n",
    "\n",
    "### Key Points\n",
    "\n",
    "- The architecture is trained end-to-end with a multi-task loss.\n",
    "- During training, it actually randomly sample balanced positve and negative examples. (in paper, it trains 128 boxes each iteration)\n",
    "- Fast RCNN uses L1 loss for bounding box prediction as opposed to L2 loss in R-CNN which is more sensitive to outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Faster RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dsfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
